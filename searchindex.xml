<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>[JVM] Java的类加载机制</title><url>https://yuancode.net/post/java/draftjvm_classloader/</url><categories><category>面经</category></categories><tags><tag>JVM</tag><tag>Java</tag></tags><content type="html"> Java的类加载机制
一般，Java的类加载过程分为三个主要步骤：加载、连接、初始化。
加载（Loading），将字节码数据从不同的数据源读取到JVM中，并映射为JVM认可的数据结构（Class对象），数据源可能是jar文件、class文件甚至网络数据源。如果输入数据不是ClassFile结构，则会抛出ClassFromatError。 加载阶段是用户参与的阶段，我们可以自定义类加载器，实现自己的类加载过程。 连接（Linking），是核心步骤，把原始的类定义信息平滑的转化到JVM运行的过程中。可以进一步分为三个步骤： 验证（Verification），虚拟机安全的重要保障，验证字节信息是否符合Java虚拟机规范，否则被认为是VerifyError，防止恶意信息或不合规的信息危害JVM的运行。 准备（Preparation），创建类或接口中的静态变量，并初始化静态变量的初始值。==侧重点在于分配所需的内存空间，不会执行进一步的JVM指令。== 解析（Resolution），将常量池中的符号引用（symbolic reference）替换为直接引用。 初始化（initialization），真正去执行类初始化的代码逻辑，包括静态字段赋值的动作，以及执行类定义中的静态初始化块内的逻辑，编译器在编译阶段就会把这部分逻辑整理好，父类型的初始化逻辑优先于当前类型的逻辑。 关于双亲委派模型：
简单说就是当类加载器（Class-Loader）试图加载某个类型的时候，除非父加载器找不到相应的类型，否则尽量将这个任务代理给当前加载器的父加载器去做。目的是避免重复加载Java类型。</content></entry><entry><title>[Spring] IoC和AOP</title><url>https://yuancode.net/post/spring_ioc_aop/</url><categories><category>面经</category></categories><tags><tag>Spring</tag><tag>IoC</tag><tag>AOP</tag></tags><content type="html"> Spring的AOP和IOC都是为了解决系统代码耦合度过高的问题。
IoC是什么？有什么好处？
IoC（Inverse of Control，控制反转）是一种设计思想，即将程序中需要手动创建的对象的控制权交由框架来进行管理，用户不需要关心具体的创建细节和依赖关系，只需要提供部分配置信息即可。过程如下：
如下图所示，IoC是依赖倒置原则的一种实现思路，而实现IoC的方法可以采用依赖注入（DI），IoC容器就是实现了IoC的一种容器。
DI：依赖注入是指将类所依赖的其他类的对象通过构造/Setter方法注入进来，而不是在当前类的内部new一个所依赖的对象。
依赖：bean对象的创建依赖于容器。 注入：bean对象中的所有属性，由容器来注入。 比如：汽车&lt;&ndash;依赖&ndash;车身&lt;&ndash;依赖&ndash;底盘&lt;&ndash;依赖&ndash;轮胎
采用DI的方式，当我们轮胎发生变化时，只需要修改轮胎类即可，不影响其他类的代码编写。
上图中，初始化一辆车需要很多new代码，而IoC容器则可以帮助我们省去这个麻烦的过程，使得我们创建实例时不需要了解他的细节，只需要提供一定的XML或者朱姐配置即可。
Spring中的IoC的实现原理是工厂模式加反射机制。
好处：
IOC容器可以自动完成对象的初始化，用户不需要编写大量复杂的初始化代码，只需要维护/提供一部分必要的配置信息即可。
用户在创建实例的时候可以不需要了解各个对象之间的依赖关系和具体的细节。
+++
AOP是什么？有什么好处？
AOP（Aspect-Oriented Programming，面向切面编程）能够将那些与业务无关，却为业务模块所共同调用的逻辑或责任（例如事务处理、日志管理、权限控制、统一全局异常处理等）封装起来，便于减少系统的重复代码，降低模块间的耦合度，并有利于未来的可扩展性和可维护性。
比如：在编写业务逻辑代码的时候，我们习惯性的都要写：日志记录，事务控制，以及权限控制等，每个子模块都要写这些代码，代码明显存在重复。这时候，我们运用面向切面的编程思想，采用横切技术，将代码中重复的部分，不影响业务逻辑的部分抽取出来，放在某个地方进行集中式的管理，调用。形成日志切面，事务控制切面。这样，我们就只需要关心业务的逻辑处理，既提高了工作的效率，又使得代码变得简洁优雅。它是面向对象编程思想的一种扩展。
Spring AOP的底层实现原理主要是代理模式，对原来目标对象创建代理对象，并且在不改变原来对象代码的情况下，通过代理对象，调用增强功能的方法，对原有业务进行增强。
AOP的代理分为动态代理和静态代理，Spring AOP中使用的是动态代理实现的AOP，AspectJ则是使用静态代理实现的AOP。
当Bean实现接口时，使用JDK动态代理1 当Bean没有实现接口时，使用CGLib动态代理1 +++
[1] JDK动态代理、CGLib动态代理：</content></entry><entry><title>[Java] String、StringBuffer、StringBuilder有什么区别?</title><url>https://yuancode.net/post/java/draftjava_string_stringbuffer_stringbuilder/</url><categories><category>面经</category></categories><tags><tag>Java</tag><tag>String</tag></tags><content type="html"> 理解Java的字符串，String、StringBuffer、StringBuilder有什么区别?
String：是Java语言非常基础和重要的类，提供了构造和管理字符串的各种基本逻辑。它是典型的Immutable类，被声明成为final class，所有属性也都是final的。也由于它的不可变性，类似拼接、裁剪字符串等动作，都会产生新的String对象。由于字符串操作的普遍性，所以相关操作的效率往往对应用性能有明显影响。
StringBuffer：是为了解决上面提到拼接产生太多中间对象的问题而提供的一个类，可以使用append或者add方法，把字符串添加到已有序列的末尾或者指定位置。StringBuffer本质是一个线程安全的可修改字符序列，它保证了线程安全，也随之带来了额外的性能开销，所以除非有线程安全的需要，不然还是推荐继续使用StringBuilder。
StringBuilder：是Java 1.5中新增的，在能力上和StringBuffer没有本质区别，但是它去掉了线程安全部分，有效减小了开销，是绝大部分情况下进行字符串拼接的首选。
+++
String为什么不可变？
不可变：对象一旦被创建后，对象所有的状态及属性在其生命周期内不会发生任何变化。
String不可变的表现就是当我们试图对一个已有的对象"abcd"赋值为"abcde"，String会新创建一个对象：
String用final修饰char数组，这个数组无法被修改，但是这个无法被修改仅仅是指引用地址不可被修改，数组本身的内容是可以修改的。
可以看出，String是不可变的，那显然仅仅靠final是远远不够的：
首先，char数组是private的，并且String类没有对外提供修改这个数组的方法，所以它初始化之后外界没有有效的手段去改变它。
其次，String类被final修饰的，也就是不可继承，避免被他人继承后破坏。
最重要的，Java作者在String的所有方法里面，都很小心地避免去修改了char数组中的数据，涉及到对char数组中数据进行修改的操作全部都会重新创建一个String对象。比如substring方法：
为什么要设计成不可变？
安全
作为最基础最常用的数据类型，String被很多Java类库用来作为参数，如果string不是固定不变的，将会引起各种安全隐患。
比如：
将可变字符串s3指向了s1，然后改变s3的值。由于StringBuilder是可变的，所以s3会直接在s1的地址上修改，导致s1的值也发生改变。于是HashSet中出现了两个相等的元素。
并且在多线程环境下，String作为不可变对象，不能被修改，多个线程同时读一个资源是没问题的，String是线程安全的。
字符串常量池的需要
字符串常量池：大量频繁的创建字符串，将会极大程度的影响程序的性能。为此，JVM为了提高性能和减少内存开销，在实例化字符串常量的时候进行了一些优化：
为字符串开辟了一个字符串常量池String Pool，可以理解为缓存区 创建字符串常量时，首先检查字符串常量池中是否存在该字符串 若字符串常量池中存在该字符串，则直接返回该引用实例，无需重新实例化；若不存在，则实例化该字符串并放入池中。 如下面的代码所示，堆内存只会创建一个String对象：
1 2 3 4 String str1 = "hello"; String str2 = "hello"; System.out.println(str1 == str2) // true 如果String允许被改变，那么我们修改str2的同时，str1也会被修改，这显然不是我们想要看到的结果。
String真的不可变吗？
其实通过反射，可以直接修改char数组的内容，当然，一般来说不会这么做。
1 2 3 4 5 6 7 8 9 10 11 12 public static void main(Stringp[] args) throws NoSuchFieldException, IllegalAccessException { String s = "hello"; System.out.println(s); // hello // 通过反射获取并修改String的私有属性value Class cls = s.getClass(); Field valueField = cls.getDeclaredField("value"); valueFiele.setAccessible(true); // 允许访问私有属性 char[] value = (char[]) valueField.get(s); // 获取s对象的value属性值 value[0] = 'd'; System.out.println(s); // dello } 总结
并不是因为char数组是final才导致String的不可变，而是为了把String设计成不可变才把char数组设置为final的。
创建不可变对象的简单策略：
不提供setter方法（包括修改字段的方法和修改字段引用对象的方法）。 将类的所有字段定义为final、private的。 不允许子类重写方法。 简单的办法是将类声明为final。 更好的方法是将构造函数声明为私有的，通过工厂方法创建对象。 如果类的字段是对可变对象的引用，不允许修改被引用对象。</content></entry><entry><title>[Java] Java常见的垃圾收集器有哪些？</title><url>https://yuancode.net/post/java/java_garbage_collector/</url><categories><category>面经</category></categories><tags><tag>Java</tag><tag>JVM</tag><tag>GC</tag></tags><content type="html"> Java（Oracle JDK）常见的垃圾收集器有哪些？
Serial ParNew CMS Parrallel G1 Serial GC： 最古老的GC； 单线程工作； 会进入“Stop-The-World”状态； Client模式下JVM的默认选项； 老年代实现单独称为Serial Old； 采用标记-整理（Mark-Compact）算法。 ParNew GC： 新生代GC实现； Serial GC的多线程版本； 配合老年代的CMS GC工作。 CMS（Concurrent Mark Sweep）GC： 基于标记-清除（Mark-Sweep）算法； 设计目标为尽量减少停顿时间； 算法原因，存在着内存碎片化的问题； 长时间运行会发生full GC，出现停顿； 由于并发（Concurrent），会占用更多CPU资源，并和用户线程争抢。 Parrallel GC： 早期JDK 8等版本中，是Server模式JVM的默认GC选择； 吞吐量优先的GC； 特点：新生代和老年代GC都是并行进行的。 G1 GC： 兼顾吞吐量和停顿时间的GC实现，Oracle JDK 9以后默认GC选项； 相比CMS，最差情况停顿时间要好很多； 仍然存在年代概念，内存并非条带式划分，是类似棋盘的一个个region； Region之间是复制算法，整体可看作标记-整理（Mark-Compact）算法，可以有效避免内存碎片，Java堆非常大的时候，优势更明显； G1的吞吐量和停顿表现都非常不错，并仍在完善，CMS已经在JDK 9中被标记为废弃（deprecated）。 +++
扩展：
垃圾收集的原理和基础概念
自动垃圾收集的前提是清楚哪些内存可以被释放。主要是两个方面，最主要部分是对象实例，都是存储在堆上的；还有方法区中的元数据等信息，例如类型不再使用，卸载该Java类。
对于对象实例收集，主要是两种基本算法，引用计数和可达性分析。
引用计数算法，就是为对象添加一个引用计数，用于记录对象被引用的情况，如果计数为0，即表示对象可回收。 引用计数算法很难处理循环引用问题。 可达性分析算法，将对象及其引用关系看作一个图，选定活动的对象作为GC Roots，然后跟踪引用链条，如果一个对象和GC Roots之间不可达，也就是不存在引用链条，那么即可认为是可回收对象。 虚拟机栈和本地方法栈中正在引用的对象、静态属性引用的对象和常量 —— GC Roots。 常见的垃圾收集算法：
复制（Copying）算法：将可用内存分为两块，每次只使用其中的一块。当这一块内存用完了，就将存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。可以避免内存碎片化，但是会有大量内存间复制的开销，空间浪费也较多。 标记-清除（Mark-Sweep）算法：首先进行标记工作，标记出所有要回收的对象，然后进行清除。存在不可避免的碎片化问题，不适合特别大的堆；一旦出现Full GC，暂停时间也过久，可能无法接受。 标记-整理（Mark-Compact）算法：类似标记-清除，但为避免内存碎片化，会在清理过程中将对象移动，确保移动后的对象占用连续的内存空间。 垃圾收集过程的理解
JVM区域总体分两类，heap区和非heap区。heap区又分：Eden Space（伊甸园）、Survivor Space(幸存者区)、Tenured Gen（老年代-养老区）。 非heap区又分：Code Cache(代码缓存区)、Perm Gen（永久代）、Jvm Stack(java虚拟机栈)、Local Method Statck(本地方法栈)。
Minor GC：新生代GC;
Major GC：老年代GC;出现了 Major GC 经常会伴随至少一次的 Minor GC（并非绝对），Major GC 的速度一般会比 Minor GC 的慢 10 倍以上；
Full GC：将整个堆进行清理；
1、一个人（对象）出来（new 出来）后会在Eden Space（伊甸园）无忧无虑的生活，直到GC到来打破了他们平静的生活。GC会逐一问清楚每个对象的情况，有没有钱（此对象的引用）啊，因为GC想赚钱呀，有钱的才可以敲诈嘛。然后富人就会进入Survivor Space（幸存者区），穷人的就直接kill掉。
2、并不是进入Survivor Space（幸存者区）后就保证人身是安全的，但至少可以活段时间。GC会定期（可以自定义）会对这些人进行敲诈，亿万富翁每次都给钱，GC很满意，就让其进入了Genured Gen(养老区)。万元户经不住几次敲诈就没钱了，GC看没有啥价值啦，就直接kill掉了。
3、进入到养老区的人基本就可以保证人身安全啦，但是亿万富豪有的也会挥霍成穷光蛋，只要钱没了，GC还是kill掉。</content></entry><entry><title>[Java] 谈谈JVM的内存区域划分，哪些区域可能发生OutOfMemoryError？</title><url>https://yuancode.net/post/java/draftjava_jvm_memory/</url><categories><category>面经</category></categories><tags><tag>Java</tag><tag>JVM</tag></tags><content type="html"> 谈谈JVM的内存区域划分，哪些区域可能发生OutOfMemoryError？
通常可以把JVM内存区域分为下面几个方面，其中，有的区域是以线程为单位，而有的区域则是整个JVM进程唯一的。
首先，程序计数器（PC, Program Counter Register）。在JVM规范中，每个线程都有自己的程序计数器，并且任何时间一个线程都只有一个方法在执行，也就是所谓的当前方法。程序计数器会存储当前线程正在执行的Java方法的JVM指令地址；或者如果是正在执行本地方法，则是未指定值（undefined）。
第二，Java虚拟机栈（Java Virtual Machine Stack），早期也叫Java栈。每个线程在创建时都会创建一个虚拟机栈，其内部保存一个个的栈帧（Stack Frame），对应着一次次的Java方法调用。
同PC，在一个时间点，对应的只会有一个活动的栈帧，通常叫做当前帧，方法所在的类叫做当前类。如果在该方法中调用了其他方法，对应新的栈帧会被创建出来，成为新的当前帧，一直到它返回结果或者执行结束。
栈帧（Stack Frame）存储着局部变量表、操作数（operand）栈、动态链接、方法正常退出或者异常退出的定义等。
第三，堆（Heap），堆是Java内存管理的核心区域，用来放置Java对象实例，几乎所有创建的Java对象实例都是直接被分配在堆上。堆被所有的线程共享，在虚拟机启动时，我们指定的“Xmx”之类的参数就是用来指定最大堆空间等指标。
堆是垃圾收集器重点照顾的区域，所以堆内会被不同的垃圾收集器进行进一步的细分，最有名的就是新生代、老年代的划分。
第四，方法区（Method Area）。这也是所有线程共享的一块内存区域，用于存储所谓的元（Meta）数据，例如类结构信息，以及对应的运行时常量池、字段、方法代码等。
由于早起的Hotspot JVM实现，很多人习惯于将方法区成为永久代（Permanent Generation）。Oracle JDK 8中将永久代移除，同时增加了元数据区（Metaspace）。
第五，运行时常量池（Run-Time Constant Pool），是方法区的一部分。Java的常量池可以存放各种常量信息，不管是编译器生成的各种字面量，还是需要再运行时决定的符号引用，所以它比一般语言的符号表存储的信息更加宽泛。
如果分析过反编译的类文件结构，就能看到版本号、字段、方法、超类、接口等各种信息，还有一项信息就是常量池。
第六，本地方法栈（Native Method Stack）。它和Java虚拟机栈非常相似，支持本地方法的调用，每个线程都会创建一个。在Oracle HotSpot JVM中，本地方法栈和Java虚拟机栈是在同一块儿区域，这完全取决于技术实现的决定，并未在规范中强制。
OOM可能发生的区域：
OOM如果通俗点说，就是JVM内存不够用了，Jacadoc中对OutOfMemoryError的解释是，没有空闲内存，并且垃圾收集器也无法提供更多内存。
隐含的意思是，在抛出OutOfMemoryError之前，通常垃圾收集器会被触发，尽其所能去清理空间。
垃圾收集器不会被触发的情况：
我们尝试去分配一个超大对象，类似一个超大数组超过堆的最大值，JVM可判断出垃圾收集器并不能解决这个问题，所以会直接抛出OutOfMemoryError。
堆内存不足是最常见的OOM原因之一，抛出的错误信息是“java.lang.OutOfMemoryError.java jeap space”，原因较多，例如：内存泄漏；堆的大小不合理（要处理比较可观的数据量，但是没有显示指定JVM堆大小或者指定数值偏小）；JVM处理引用不及时，导致堆积，内存无法释放。 Java虚拟机栈和本地方法栈也会导致出现OOM问题。比如：无限递归，JVM实际会抛出StackOverFlowError，如果JVM试图去扩展栈空间失败，则会抛出OutOfMemoryError。 老版本Oracle JDK，永久代的大小有限制，并且JVM对其垃圾回收不积极，所以也会出现OutOfMemoryError，尤其是存在大量动态类型生成的场合。但是，随着元数据区的引入，方法区内存已经不再那么窘迫。 直接内存不足，也会导致OOM。 图1. Java虚拟机运行时数据区1
图2. 实际中Java进程内存占用2
这张图反映了实际中Java进程内存占用，与规范中定义的JVM运行时数据区之间的差别，它可以看做是运行时数据区的一个超集。
具体JVM的内存结构，其实取决于其实现，不同厂商或同一厂商的不同版本，都有可能存在一定差异。
+++
[1]：深入理解Java虚拟机：JVM高级特性与最佳实践（第3版）第2章
[2]：[极客时间] Java核心技术面试精讲 第25讲</content></entry><entry><title>[Java] Java程序运行在Docker等容器环境有哪些新问题？</title><url>https://yuancode.net/post/java/java_run_in_docker/</url><categories><category>面经</category></categories><tags><tag>Docker</tag><tag>Java</tag></tags><content type="html"> Java程序运行在Docker等容器环境有哪些新问题？
Docker的内存、CPU等资源限制是通过CGroup（Control Group）实现的，早期的JDK版本（8u131之前）并不能识别这些限制，进而会导致一些基础问题： 如果未配置合适的JVM堆和元数据区、直接内存等参数，Java就有可能试图使用超过容器限制的内存，最终被容器OOM kill，或者自身发生OOM。 错误判断了可获取的CPU资源，例如，Docker限制了CPU的核数，JVM就可能设置不合适的GC并行线程数等。 从应用打包、发布等角度触发，JDK自身就比较大，生成的镜像就更为臃肿。当打包镜像较多的时候，存储开销就开始明显了。 如果考虑到微服务、Serverless等新的架构和场景，Java自身的大小、内存占用、启动速度，都存在一定局限性，因为Java早起的优化大多是针对长时间运行的大兴服务器端应用。 +++
扩展：
Docker到底有什么特别？
Docker虽然看起来和虚拟机非常相似，比如，它也有自己的shell，能独立安装软件包，运行时与其他容器互不干扰。但是Docker并不是一种完全的虚拟化技术，而是一种轻量级的隔离技术。
基于namespace，Docker为每个容器提供了单独的命名空间，对网络、PID、用户、IPC通信、文件系统挂载点等实现了隔离。对于CPU、内存、磁盘IO等计算资源通过CGroup进行管理。
Docker仅在类似Linux内核之上实现了有限的隔离和虚拟化，并不是独立运行一个新的操作系统，同时Docker并未完全隐藏底层信息。
容器环境对于计算资源的管理方式是全新的，CGroup作为相对比较新的技术，历史版本的Java在不做改动的情况下，无法自然地理解相应的资源限制。 namespace对于容器内的应用细节增加了一些微妙的差异，比如jcmd、jstack等工具会依赖于“/proc”下面提供的部分信息，但是Docker的设计改变了这部分信息的原有结构，我们需要对原有工具进行修改才能使用这种变化。 从JVM运行机制的角度，为什么这些“沟通障碍”会导致OOM问题？
这个问题实际反映了JVM如何根据系统资源（内存、CPU等）情况，在启动时设置默认参数。
Ergonomics机制1：
系统内存大小：X
堆大小设置为X的1/64，堆最大值为X的1/4。
JVM检测到的系统CPU核数，直接影响到Parallel GC的并行线程数目和JIT complier线程数目，甚至是应用中ForkJoinPool2等机制的并行等级。
这些默认参数，是根据通用场景选择的初始值。但是由于容器环境的差异，Java的判断很可能是基于错误信息做出的。
并且，JVM的一些原有诊断或者备用机制也会收到影响。为了保证服务的可用性，一种常见的选择是依赖“-XX:OnOutOfMemoryError”功能，通过调用处理脚本的形式来做一些补救措施，比如自动重启服务等。但是这种机制是基于fork实现的，当Java进程已经过度提交内存时，fork新的进程往往已经不可能正常运行了。
那么如何解决这些问题？
如果能够将JDK升级到新的版本，问题也就迎刃而解了。
针对这种情况，JDK9引入了一些实验性参数，方便Docker和Java“沟通”：
1 2 -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap 注意：这两个参数顺序敏感，且仅支持Linux环境。
如果升级到JDK10或者更新的版本，问题就更简单了。Java对Docker的支持已经比较完善，默认自适应各种资源限制和实现差异。UseCGroupMemoryLimitForHeap已被标记为废弃。
新增了参数用于明确指定CPU核心的数目。
1 -XX:ActiveProcessorCount=N 如果暂时只能使用老版本的JDK，那么需要明确设置堆、元数据区等内存区域大小，保证Java进程的总大小可控。
例如：
1 $ docker run -it --rm --name yourcontainer -p 8080:8080 -m 800m rope/your-java-container:openjdk 额外配置一下环境变量，指定JVM堆的大小：
1 -e JAVA_OPTIONS='-Xmx300m' 明确配置GC和JIT并行线程数目，以避免二者占用过多计算资源。
1 2 -XX:ParallelGCThreads -XX:CICpmpilerCount 另外，在很多场景中还会发现JAVA在Docker环境中会意外使用Swap，可以配置以下参数：
1 -XX:MaxRAM=`cat /sys/fs/cgroup/memory/memory.limit_in_bytes` 也可以指定Docker运行参数，例如：
1 --memory-swappiness=0 这是受操作系统Swappiness机制3影响，当内存小号达到一定门限，OS会试图将不活跃的进程换出（Swap out），上面的参数有显式关闭Swap的作用。
+++
[1] Ergonomics机制：【Java 8 GC 调优】Ergonomics [2] ForkJoinPool：Java-ForkJoinPool详解 [3] Swappiness机制：https://en.wikipedia.org/wiki/Swappiness</content></entry><entry><title>[Java] Java有几种文件拷贝方式？</title><url>https://yuancode.net/post/java/java_copy/</url><categories><category>面经</category></categories><tags><tag>IO</tag><tag>Java</tag></tags><content type="html"> Java有几种文件拷贝方式？哪一种最高效？
利用java.io类库，直接为源文件构建一个FileInputStream读取，然后再为目标文件构建一个FileOutputStream，完成写入工作。
1 2 3 4 5 6 7 8 9 10 public static void copyFileByStream(File source, File dest) throws IOException { try(InputStream is = new FileInputStream(source); OutputStream os = new FileOutputStream(dest);) { byte[] buffer = new byte[1024]; int length; while((length = is.read(buffer)) > 0) { os.write(buffer, 0, length); } } } 利用java.nio类库提供的transferTo或transferFrom方法实现。
1 2 3 4 5 6 7 8 9 public static void copyFileByChannel(File source, Filr dest) throws IOException { try(FileChannel sourceChannel = new FileInputStream(source).getChannel(); FileChannel targetChannel = new FileOutputStream(dest).getChannel();) { for(long count = sourceChannel.size(); count > 0; ) { long transferred = sourceChannel.transferTo(sourceChannel.position(), count, targetChannel); count -= transferred; } } } 利用Java标准库本身提供的几种File.copy实现。
一般来说，NIO的transferTo/transferFrom的方式更快，因为它更能利用好现代操作系统的底层机制，避免不必要的拷贝和上下文切换。</content></entry><entry><title>[Java] 谈谈 Java 反射机制，动态代理是基于什么原理?</title><url>https://yuancode.net/post/java/draftjava_reflect/</url><categories><category>面经</category></categories><tags><tag>Java</tag><tag>reflect</tag></tags><content type="html"> 谈谈 Java 反射机制，动态代理是基于什么原理?
反射机制是Java提供的一种基础功能，赋予程序在运行时自省（introspect）的能力。通过反射我们可以直接操作类或者对象，比如获取某个对象的类定义，获取类声明的属性和方法，调用方法或者构造对象，甚至可以运行时修改类定义。
动态代理是一种方便运行时动态构建代理、动态处理代理方法调用的机制，很多场景都是利用类似机制做到的，比如用来包装RPC调用、面向切面的编程（AOP）。
实现动态代理的方式很多，比如JDK自身提供的动态代理，就是主要利用了上面提到的反射机制。还有其他的实现方式，比如利用传说中更高性能的字节码操作机制，类似ASM、cglib（基于ASM）、Javassist等。
+++
扩展：
1. 动态代理解决了什么问题？</content></entry><entry><title>[Java] Exception和Error有什么区别？</title><url>https://yuancode.net/post/java/java_exception_and_error/</url><categories><category>面经</category></categories><tags><tag>Java</tag><tag>Exception</tag><tag>Error</tag></tags><content type="html"> 请对比 Exception 和 Error，另外，运行时异常与一般异常有什么区别?
Exception和Error都是继承了Throwable类，在Java中只有Throwable类型的实例才可以被抛出(throw)或者捕获(catch)，它是异常处理机制的基本组成类型。
Exception和Error体现了Java平台设计者对不同异常情况的分类。Exception是程序正常运行中，可以预料的意外情况，可能并且应该被捕获，进行相应处理。
Error是指在正常情况下，不大可能出现的情况，绝大部分的Error都会导致程序（比如JVM自身）处于非正常的、不可恢复状态。既然是非正常情况，所以不便于也不需要捕获，常见的比如OutOfMemoryError之类，都是Error的子类。注意：Error是Throwable不是Exception虽然它不可查。
Exception又分为受检查(checked)异常和未检查(unchecked)异常，可检查异常在源代码里必须显示地进行捕获处理，这是编译期检查的一部分。
不检查异常就是所谓的运行时异常，类似NullPointerException（空指针）、ArrayIndexOutOfBoundsException（下标越界）之类，通常是可以编码避免的逻辑错误，具体根据需要来判断是否需要捕获，并不会在编译期强制要求。
+++
扩展：
1. NoClassDefFoundError和ClassNotFoundException有什么区别？
NoClassDefFoundError:
NoClassDefFoundError错误的发生是因为Java虚拟机在编译时能找到合适的类，而在运行时不能找到合适的类导致的错误。（类加载过程中没有办法找到对应的class文件。）比如编译通过后，手动删除引用的某个class文件、修改引用的jar包名称。
NoClassDefFoundError是Error，是未检查（unchecked）异常，因此不需要使用try-catch或者finally语句块包裹。
ClassNotFoundException：
和编译期无关，当在代码中显示加载类（使用Class.forName()1）时没有找到对应的类，则会抛出ClassNotFoundException。例如加载SQL驱动时，对应的类加载器找不到驱动类。 ClassNotFoundException是受检查（checked）异常，因此需要使用try-catch或者finally语句块包裹。 2. 这段代码反映了异常处理中哪些不当之处？
第一段代码：
1 2 3 4 5 6 7 try { // 业务代码 // ... Thread.sleep(1000L); } catch (Exception e) { // Ignore it } 第一，尽量不要捕获类似Exception这样的通用异常，而是应该捕获特定异常，Thread.sleep()抛出的是InterruptedException。
日常开发和合作中，我们读代码的机会往往超过写代码，软件工程是门协作的艺术，所以我们有义务让自己的代码能够直观地体现出尽量多的信息，而泛泛的Exception之类，恰恰隐藏了我们的目的。另外，我们也要保证程序不会捕获到我们不希望捕获的异常。
第二，不要生吞（swallow）异常。这是处理异常中要特别注意的事情，因为很可能会导致非常难以诊断的诡异情况。
第二段代码：
1 2 3 4 5 6 try { // 业务代码 // ... } catch (IOException e) { e.printStackTrace(); } 这段代码作为一段实验代码，是没有任何问题的，但是在产品代码中，通常都不允许这样处理。
printStackTrace() 的文档开头写到“Prints this throwable and its backtrace to the standard error stream”。在稍微复杂一些的生产系统中，标准出错（STERR）不是个合适的输出选项，因为很难判断出到底输出到了哪里。
尤其是对于分布式系统，如果发生异常，但是无法找到堆栈轨迹（stacktrace），相当于为诊断设置障碍。因此，最好使用产品日志，详细地输出到日志系统里。
Throw early, catch late原则：
1 2 3 4 5 public void readPreferences(String fileName) { // ...perform operations InputStream in = new FileInputStream(fileName); // ...read the preferences file... } 如果fullName是null，那么程序会抛出NullPointerException，但是没有第一时间暴露问题，堆栈信息可能让人费解。
1 2 3 4 5 6 public void readPreferences(String fileName) { Objects.requireNonNull(fileName); // ...perform operations InputStream in = new FileInputStream(fileName); // ...read the preferences file... } 经过修改，问题便可以"throw early"，对应的异常信息便非常直观了。
try-catch带来的开销：
try-catch代码段会产生额外的性能开销，往往会影响JVM对代码进行优化，所以建议仅捕获有必要的代码段，尽量不要一个大的try包住整段的代码；
Java每实例化一个Exception，都会对当时的栈进行快照，这是一个相对比较重的操作。如果发生的非常频繁，这个开销就不能被忽略了
+++
[1] Class.forName()：Class.forName()用法详解</content></entry><entry><title>[Java] 强引用、软引用、弱引用、虚引用</title><url>https://yuancode.net/post/java/java_reference/</url><categories><category>面经</category></categories><tags><tag>Java</tag><tag>JVM</tag><tag>Reference</tag></tags><content type="html"> 在JDK 1.2版本之后，Java对引用的概念进行了扩充，将引用分为强引用（Strongly Re-ference）、软引用（Soft Reference）、弱引用（Weak Reference）和虚引用（Phantom Reference）4种，这4种引用强度依次逐渐减弱。
强引用、软引用、弱引用、幻象引用有什么区别?具体使用场景是 什么?
不同的引用类型，主要体现的是**对象不同的可达性（reachable）**状态和对垃圾收集的影响。
强引用：最传统的“引用”的定义，是指在程序代码之中普遍存在的引用赋值。只要强引用关系还在，GC（垃圾收集器）就永远不会回收掉被引用的对象。
1 Object obj = new Object(); 软引用：描述一些还有用，但非必须的对象。将要发生内存溢出异常之前，会把这些对象列进回收范围之中进行第二次回收，如果此次回收还没有足够的内存，才会抛出内存溢出异常。
1 2 // SoftReference实例来保存一个对象的软引用。 SoftReference aSoftRef = new SoftReference(aRef); 弱引用：描述那些非必须对象，但是它的强度比软引用更弱一些，只能生存到下一次垃圾收集发生为止。无论内存是否足够，都会回收掉只被弱引用关联的对象。
虚引用：也称为“幽灵引用”或者“幻影引用”，不会影响对象生存时间。唯一目的：为了能在这个对象被收集器回收时收到一个系统通知。
+++
扩展：
对象可达性状态流转
可达性级别（reachability level）：
强可达（Strongly Reachable）：当一个对象可以有一个或多个线程可以不通过各种引用访问到的情况。
软可达（Softly Reachable）：就是当我们只能通过软引用才能访问到对象的状态。
弱可达（Weakly Reachable）：无法通过强引用或者软引用访问，只能通过弱引用访问时的状态。十分接近finalize状态的时机，当弱引用被清除的时候，就符合finalize的条件了。
幻象可达/虚可达（Phantom Reachable）：没有强、软、弱引用关联，并且finalize过了，只有虚引用指向这个对象的时候。
不可达（unreachable）：对象可以被清除了。
判断对象可达性，是JVM垃圾收集器决定如何处理对象的一部分考虑。</content></entry><entry><title>[Java] 谈谈final、finally、finalize有什么不同？</title><url>https://yuancode.net/post/java/java_final_finally_finalize/</url><categories><category>面经</category></categories><tags><tag>Java</tag></tags><content type="html"> 谈谈final、finally、finalize有什么不同？
final：可以用来修饰类、方法、变量，分别有不同的意义： 类（class）：不可以继承扩展 方法：不可以重写（override） 变量：不可以修改 finally：Java保证重点代码一定会被执行的一种机制。可以使用try-finally或者try-catch-finally来进行类似关闭JDBC连接、保证unlock锁等动作。 finalize：是基础类java.lang.Object的一个方法，它设计目的是保证对象在被垃圾收集前完成特定资源的回收。finalize机制现在已经不推荐使用，并且在JDK 9开始被标记为deprecated。 +++
final：
我们可以将方法或者类声明为final，这样可以明确告知别人，这些行为是不许修改的。 有些Java类同样被声明为final，这可以有效避免API使用者更改基础功能，某种程度上，这事保证平台安全的必要手段。 使用final修饰参数或者变量，也可以清楚地避免意外赋值导致的编程错误。 final变量产生了某种程度的不可变（immutable）效果，所以，可以用于保护只读数据，尤其是在并发编程中，因为明确地不能再赋值final变量，有利于减少额外的同步开销，也可以省去一些防御性拷贝的必要。 finally的例外情况：
1 2 3 4 5 6 try { // do something System.exit(1); } finally { System.out.println("Print from finally"); } 这段代码中的finally并不会被执行，这与上面的保证重点代码一定会被执行矛盾，这种情况属于特例。
关于finalize：
已不推荐使用。 简单来说，你无法保证finalize什么时候执行，执行的是否符合预期。使用不当会影响性能，导致程序死锁、挂起等。 回收资源可以选择上面提到的try-with-resources或者try-finally机制。如果确实需要额外处理，可以考虑Java提供的Cleaner机制或者其他替代方法。 扩展：
final不是immutable
final并不等同于immutable，比如：
1 2 3 4 5 final List&lt;String> strLsit = new ArrayList&lt;>(); strList.add("Hello"); strList.add("World"); List&lt;String> unmodifiableStrList = List.of("hello", "world"); unmodifiableStrList.add("again"); final只能约束strList这个引用不可以被赋值，但是strList对象行为不被final影响，添加元素等操作是完全正常的。如果我们真的希望对象本身是不可变的，那么需要相应的类支持不可变的行为。
上面的例子中，List.of方法 创建的本身就是不可变的List，第5行代码会导致在运行时抛出异常。
某种意义上说，Java目前没有原生的不可变支持，如果要实现immutable类，需要做到：
将class自身声明为final。 将所有成员变量定义为private和final，并且不实现setter方法。 通常构造对象时，成员变量使用深度拷贝来初始化，而不是直接赋值，这是一种防御措施，因为你无法确定输入对象不被其他人修改。 如果确实要实现getter方法，或者其他可能会返回内部状态的方法，使用copy-on-write原则，创建私有的copy。 finalize是否真的如此不堪？
finalize的执行是和垃圾收集关联在一起的1，一旦实现非空的finalize方法，就会导致相应对象回收呈现数量级上的变慢。
因为finalize被设计成在对象被垃圾收集前调用，这就意味着实现了finalize方法的对象是个“特殊公民”，JVM要对它进行额外处理。finalize本质上成为了快速回收的阻碍者，可能导致对象经过多个垃圾收集周期才能被回收。
即使我们使用System.runFinalization()2主动告诉JVM积极一些，但是这种方式只能起到部分效果，finalize仍然是不可预测、不能保证的。实践中，因为finalize拖慢GC，导致大量对象堆积，也是一种典型的导致OOM的原因。
从另一个角度，我们要确保回收资源就是因为资源是有限的，GC时间的不可预测，可能会极大加剧资源占用。这意味着对于消耗非常高频的资源，不可以期望finalize来承担释放资源的主要职责，只能让其作为“守门员”。
同时，finalize海货掩盖资源回收出错时的出错信息：
1 2 3 4 5 6 7 8 9 10 11 12 13 private void runFinalizer(JavaLangAccess jla) { // ... 省略部分代码 try { Object finalizee = this.get(); if(finalizee != null &amp;&amp; !(finalizee instanceof java.lang.Enum)) { jla.invokeFinalize(finalizee); // Clear stack slot containing this variable, to decrease // the chances of false retention with a conservative GC finalizee = null; } } catch (Throwable x) { } super.clear(); } **Throwable被生吞（swallow）了。**这意味着一旦出现异常或者出错，将得不到任何有效信息。
有没有什么机制可以替代finalize？
Java目前正在逐步使用java.lang.ref.Cleaner来替换掉原有的finalize实现。Cleaner的实现利用了幻象引用（PhantomReference），这事一种常见的所谓的post-mortem清理机制。利用幻象引用和引用队列，可以保证对象被彻底销毁前做一些类似资源回收的工作（比如关闭文件描述符），它比finalize更加轻量、更加可靠。
每个Cleaner的操作都是独立的，它有自己的运行线程，可以避免意外死锁。不过改善程度仍然有限，还是只适合作为一种最后的保证手段。
+++
[1] ：深入理解Java虚拟机：JVM高级特性与最佳实践（第3版）第3章
[2] System.runFinalization()：System.gc()和System.runFinalization()</content></entry><entry><title>[网络协议] 网络协议是怎样基于OSI体系分层的？</title><url>https://yuancode.net/post/draftnet_osi/</url><categories><category>网络协议</category></categories><tags><tag>Web</tag><tag>Network</tag><tag>OSI</tag></tags><content type="html"> 网络协议是怎样基于OSI体系分层的？
1. OSI协议分层体系 1.1 协议分层与软件分层 1.2 代理服务器与OSI七层协议</content></entry><entry><title>[网络协议] 为何TCP连接要经由三次握手才能建立？</title><url>https://yuancode.net/post/draftnet_tcp/</url><categories><category>网络协议</category></categories><tags><tag>Web</tag><tag>Network</tag><tag>TCP</tag></tags><content type="html"> TCP三次握手的流程及优化 TCP四次挥手的流程及优化 TCP引入的队头阻塞问题 HTTP3协议帧格式 HTTP3连接迁移流程 0. 问题 0.1 为什么TCP建立连接要经过三次握手？多一次少一次行不行？ SYN（Synchronize Sequence Numbers），同步序列编号；
ACK（Acknowledge Character），确认字符；
SEQ（Sequence Number），序列号。
三次握手的过程：
一开始，C端（Client，客户端）与S端（Server，服务端）都处于CLOSED状态。C端主动打开连接，服务端被动打开连接，结束CLOSED状态，开始监听，进入LINSTEN状态。 一次握手🤝：
C端会随机初始化序号seq=x（client_isn），将此序号置于TCP首部的“序号”字段中 同时把SYN=1，表示这是SYN握手报文。 接着把第一个SYN报文发送给S端，表示向S端发起连接，该报文不包含应用层数据，之后C端处于SYN-SENT（同步已发送）状态。 二次握手🤝：
S端收到C端的SYN报文后
首先服务端也随机初始化自己的序号seq=y(server_isn)，将此序号填入TCP首部的“序号”字段中。 其次把TCP首部的“确认应答号”字段填入ack=x+1（client_isn+1）。 表示收到了C端x之前的数据，希望客户端下次发送的数据从x+1开始。 接着把SYN=1，ACK=1，表示这是一个SYN握手和ACK确认应答报文。 最后把该报文发送给C端，该报文也不包含应用层数据，之后服务端处于SYN-RCVD（同步已接收）状态。
三次握手🤝：
C端收到S端报文后，再向S端回应最后一个应答报文。 首先ACK=1。 其次“确认应答号”字段填入ack=y+1（server_isn+1）。 表示收到了S端y之前的数据，希望下次S端发送的数据从y+1开始。 最后把报文发送给服务端。 这次报文可以携带C端到S端的数据，之后C端处于ESTABLISHED（连接已建立）状态。S端收到C端的应答报文后，也进入ESTABLISHED（链接已建立）状态。 三次握手动态示意图1：
为什么必须是三次？两次/四次不行吗？
三次握手才可以阻止历史重复连接
三次握手才可以同步双方的初始序列号
三次握手才可以避免重复建立连接
以上三点，两次握手均不能做到。而四次握手可以做到，但是相对三次握手来说是额外的一次开销。
由于以上三个问题，因此我们需要三次握手来确认这个过程。
0.2 为什么TCP断开连接需要四次挥手？ 双方都可以主动断开连接，断开连接后主机中的“资源”将被释放。
四次挥手过程：
一次挥手👋🏻：
C端打算关闭连接，发送一个TCP首部FIN=1的报文，即FIN报文，之后C端进入FIN_WAIT_1状态。 二次挥手👋🏻：
S端收到该报文后，向C端发送ACK应答报文，S端进入CLOSED_WAIT状态。 三次挥手👋🏻：
C端收到S端的ACK应答报文后，进入FIN_WAIT_2状态。 等待S端处理完数据，向客户端发送FIN报文，S端进入LAST_ACK状态。 四次挥手👋🏻：
C端收到S端的FIN报文后，回一个ACK应答报文，之后进入TIME_WAIT状态。 S端收到ACK应答报文后，进入CLOSED状态，S端已经完成连接的关闭。 C端在经过2MSL一段时间后，自动进入CLOSED状态，至此客户端也完成了连接的关闭。 每个方向都需要一个FIN和ACK，因此是四次挥手。
四次握手示意图1：
为什么要四次挥手？
关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据了但是还能接收数据。 服务器收到客户端的 FIN 报文时，先回一个 ACK 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 FIN 报文给客户端来表示同意现在关闭连接。 从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 ACK 和 FIN 一般都会分开发送，从而比三次握手导致多了一次。
为什么要等待2MSL?
MSL(Maximum Segment Lifetime)：一段 TCP 报文在传输过程中的最大生命周期。
等2MSL是为了确认S端是否收到C端发出的ACK确认报文，单纯的向S端发出ACK确认报文后，无法确定S端能接收到该段报文。 2MSL 即是服务器端发出为 FIN 报文和客户端发出的 ACK 确认报文所能保持有效的最大时长。 服务器端在 1MSL 内没有收到客户端发出的 ACK 确认报文，就会再次向客户端发出 FIN 报文： 如果客户端在 2MSL 内，再次收到了来自服务器端的 FIN 报文，说明服务器端由于各种原因没有接收到客户端发出的 ACK 确认报文。 客户端再次向服务器端发出 ACK 确认报文，计时器重置，重新开始 2MSL 的计时。 否则客户端在 2MSL 内没有再次收到来自服务器端的 FIN 报文，说明服务器端正常接收了 ACK 确认报文，客户端可以进入 CLOSED 阶段，完成“四次挥手”。 所以，客户端要经历时长为 2SML 的 TIME-WAIT 阶段;这也是为什么客户端比服务器端晚进入 CLOSED 阶段的原因。 1. TCP协议的发展历史 1.1 TCP编程示例 1.2 TCP/IP协议发展 1995：v1.0
1999：v1.1
2009：v1.2
2018：v1.3
2. TCP连接的同步要素 TCP为什么要建立连接？
TCP有连接概念的核心原因是TCP需要传输有序字节流。
2.1 连接的定义 TCP连接（源地址，源端口，目的地址，目的地址） 对于IPv4地址，单机最大TCP连接数为2(32+16+32+16) Server1连接Server2，Server2的端口已经固定时，能够建立的TCP连接数是65535（2^16 - 1）。 QUIC连接：Connection ID 2.2 TCP头部 2.3 TCP常用选项 3. TCP状态机的变迁流程 3.1 TCP握手流程 TCP建立连接三次握手的主要目的是同步Sequence，其他SYN、MSS是辅助。
3.2 TCP状态机 4. TCP为HTTP2引入的队头阻塞问题 4.1 TCP层的有序字符流 4.2 HTTP2协议的遗留问题：队头阻塞 如果Client向Server发送了序号1-3的报文，但是报文1丢失，那么报文2-3都会被阻塞，不会被传递到应用进程。
HTTP2支持多路复用，在丢失一个报文以后，那么均会受到影响。
4.3 队头阻塞的解决 不再使用TCP，改用UDP协议。（HTTP3就是基于UPD来设计的）
那么丢失的报文应该如何处理呢？HTTP3选择交给QUIC层来处理。
相当于将TCP一分为二：进程和报文关联起来的工作交给UDP，拥塞控制、丢失重传交给QUIC层。
在原本的HTTP2中，TLS中的加密解密是依赖于TCP的，在HTTP3中TLS被重新定义，位于QUIC层。
5. HTTP3协议的特点 5.1 降低建立连接成本 5.2 HTTP3报文头部 Connection ID定义于Packet Header中，还包括其他一些内容是不允许被加密的。比如HTTP3已经不再通过源地址与源端口来确认身份，而是依赖于Connection ID来确认。
QUIC Frame Header用于解决有序字节流、丢包重传问题。
HTTP3 Frame Header解决HTTP3语义的问题。
HTTP Message含义不变。
5.3 QUIC Stream Frame头部 TCP中有序字节流靠Sequence实现，HTTP3依赖Offset解决有序字节流。
Stream ID 和 Length对应TCP中的相应内容。
5.4 HTTP3 Frame头部 6. 总结 TCP连接是由客户端IP地址与端口、服务器IP地址与端口4元素确定的。 由于IPv4地址长度是32位，端口长度是16位，故IP、端口都确定的服务器上能够支持的最大连接数是232+16。 TCP建立三次握手时，除了同步Sequence序列号外，还可以确定MSS、窗口扩大、时间戳等功能的开启。 在TCP的三次握手过程中，客户端会经历SYN_SENT状态，而服务器会经历SYNC_RCV状态。 在TCP的四次挥手流程中，主动端会经历FIND_WAIT1、FIND_WAIT2和TIME_WAIT状态，被动端则会经历CLOSE_WAIT、LAST_ACK状态。 在TCP上实现的多路复用，必然面临队头阻塞问题。 HTTP3基于UDP后，没有了队头阻塞，但必须在QUIC Stream层重新实现有序字符流(Offset)。 HTTP3的连接迁移功能通过Packet Header中的Connection ID实现。 +++
[1] 三次握手动态示意图：图片来自“三次握手，四次挥手”这么讲，保证你忘不了</content></entry><entry><title>[网络协议] 在浏览器上输入URL到主页显示，经历了哪些步骤？</title><url>https://yuancode.net/post/draftnet_url_index/</url><categories><category>网络协议</category></categories><tags><tag>Web</tag><tag>Network</tag></tags><content type="html"> 在浏览器上输入URL到主页显示，经历了哪些步骤？
DNS解析：将域名解析成IP地址； TCP连接：根据IP地址找到服务器连接（三次握手）； 发送HTTP请求； 服务器处理请求并返回HTTP报文； 浏览器解析，渲染页面； 断开连接：关闭TCP连接（四次挥手）。 1. 浏览器发起HTTP请求的逻辑是什么？ 1.1 HTML DOM树 首先考虑我们的浏览器在为我们展示出一个页面之前发生了什么？
前提应该是浏览器可以知道页面的布局，比如我们的页面大小，不同div所占位置及大小，其次是布局之中的内容，这一过程来自渲染树1。布局来自CSS树1，而内容来自DOM树1。
不过在浏览器“画”出了布局和其中的内容以后，我们可以发现可能还有一些视频、图片暂时无法查看。这是由于浏览器在渲染页面时分为了两部分：关键路径2和非关键路径2。
1.2 浏览器是如何渲染页面的？ 1.3 应用层视角：Web请求 域名解析到IP地址：需要进行多级的DNS服务器解析，此过程中使用的是UDP协议。
1.4 HTTP协议是怎样工作的？ 为什么HTTP协议3是客户端先发然后服务器才能应答？
一般来说服务器才有固定IP，且一般情况下服务器所开放的端口也是固定的（80/443），这也就意味着Client可以主动建立连接。
服务器同时为非常多的客户进行服务，并且Client在对某个页面发送请求的时候，同时发送了非常多的请求。服务器只有在收到Client的请求以后，才能知道Client需要什么资源/信息，从而返回给Client。
1.5 表示层：TLS/SSL是怎样工作的？ 1.6 传输层：TCP协议是怎么工作的？ 1.7 网络层：IP协议是怎样工作的？ 2. 浏览器的Network抓包面板 2.1 Chrome抓包：Network面板 概览：最多6个连接，主要用于优化用户体验，尽量让DOM线（第一根竖直的线）前移。
2.2 控制器的常用功能 要跨页面加载保存请求：Preserve log 是否使用浏览器缓存 手动清除浏览器缓存：右键点击请求选择 Clear Browser Cache 设置网络性能 静态站点的离线浏览：Offline 调整网速模拟用户体验：Network Throttling 2.3 过滤器的常用功能 基于资源类型 多类型：按住Command或Ctrl 基于访问时间：拖动概览面板和时间线 隐藏Data URLs：CSS图片等小文件以BASE64格式嵌入HTML中，减少HTTP请求数。 Filter输入过滤器：多个条件以空格分隔，含义为 And 与 基于域名：domain，可使用*通配符 找出所有缓存资源：is:from-cache 找出特定的请求方法：method has-response-header：显示包含指定HTTP响应标头的资源 larger-than：显示较大的资源（以字节为单位） status-code：匹配响应码 scheme：匹配HTTP或者HTTPS 3. 总结 OSI将协议分层后，可以让软件实现层面解耦合，降低了系统复杂性，允许各层协议独立演进。 浏览器依据DOM树及渲染规则，会发出多个HTTP请求。 DNS协议可以将域名转化为IP地址。 OSI协议分层只是参考概念，许多实际的协议无法与其一一对应。 IP协议保障了主机与主机间的报文可达。 传输层协议提供了进程与进程间的报文可达。 TCP协议提供了可靠的字节流传输。 TLS/SSL协议提供了机密性、完整性及通讯双方的身份鉴别。 +++
[1] 渲染树、CSS树、DOM树：https://blog.csdn.net/egegerhn/article/details/123121149
[2] 关键渲染路径、非关键渲染路径：前端内容。
[3] HTTP协议：自描述协议。HTTP协议详解</content></entry><entry><title>[Mysql] 谈谈Mysql支持的事务隔离级别，以及悲观锁和乐观锁。</title><url>https://yuancode.net/post/draftmysql_isolation_level_and_lock/</url><categories><category>面经</category></categories><tags><tag>Java</tag><tag>Mysql</tag></tags><content type="html"> 谈谈 MySQL 支持的事务隔离级别，以及悲观锁和乐观锁的原理和应用场景?
隔离级别（Isolation Level），就是在数据库事务中，为保证并发数据读写的正确性而提出的定义，它并不是Mysql专有的概念。事务的隔离级别受到数据库的限制，不同的数据库支持的隔离级别不一定相同
隔离级别 以最常见的MySQL InnoDB引擎为例，它是基于MVCC（Multi-Versioning Concurrency Control）和锁的复合实现，按照隔离程度从低到高，Mysql事务隔离级别分为四个不同层次：
读未提交（Read uncommitted），就是一个事务能够按到其他事务尚未提交的修改，最低水平的隔离，允许脏读1出现。 读已提交（Read committed），事务能够看到的数据都是其他事物已经提交的修改，也就是保证不会看到任何中间性状态，当然脏读也不会出现。读已提交并不保证再次读取时能够获取同样的数据，也就是允许其他事务并发修改数据，允许不可重复读和幻象读（Phantom Read）出现。 可重复读（Repeatable reads），保证同一个事务中多次读取的数据是一致的，这是MySql InnoDB引擎的默认隔离级别，但是和一些其他数据实现不同的是，可以简单认为MySQL在可重复读级别不会出现幻象读。 串行化（Serializable），并发事务之间是串行化的，通常意味着读取需要获取共享读锁，更新需要获取排他写锁，如果SQL使用WHERE语句，还会获取区间锁（MySQL以GAP锁形式实现，可重复读级别中默认也会使用），这是最高的隔离级别。 乐观锁和悲观锁 乐观锁和悲观锁：是并发编程的基本概念。主要区别在于，操作在共享数据时，“悲观锁”认为数据出现冲突的可能性更大，而“乐观锁”则是认为大部分情况下不会出现冲突，进而决定是否采取排他性措施。
反映到MySQL数据库应用开发中，悲观锁一般就是利用类似SELECT ... FOR UPDATE这样的语句，对数据加锁，避免其他事务意外修改数据。乐观锁则与Java并发包中的AtomicFieldUpdater类似，也是利用CAS机制，并不会对数据加锁，而是通过对比数据的时间戳或者版本号，来实现乐观锁需要的版本判断。
MVCC，其本质就可以看做是乐观锁机制，而排他性的读写锁、双阶段锁等则是悲观锁的实现。
+++
[1] 脏读：脏读又称无效数据的读出，是指在数据库访问中，事务T1将某一值修改，然后事务T2读取该值，此后T1因为某种原因撤销对该值的修改，这就导致了T2所读取到的数据是无效的。（脏读一般是针对于update操作的）</content></entry><entry><title>[Java] Java 提供了哪些 IO 方式? NIO 如何实现多路复用?</title><url>https://yuancode.net/post/java/draftjava_io_nio/</url><categories><category>面经</category></categories><tags><tag>Java</tag></tags><content type="html"> Java 提供了哪些 IO 方式? NIO 如何实现多路复用?
java.io (Blocking I/O)
BIO属于同步阻塞IO模型。应用程序发起read调用后，会一直阻塞，直到内核把数据拷贝到用户空间。也就是说在读、写动作完成之前，线程会一直阻塞在那里。
好处是代码比较简单直观，缺点则是IO效率和扩展性存在局限性，容易成为应用性能的瓶颈。
java.nio (Java1.4，Non-blocking/New I/O)
提供了Channel、Selector、Buffer等抽象。
可以构建多路复用的、同步非阻塞IO程序。
java.nio2(Java7 异步非阻塞IO方式)
java.nio的改进版，异步IO模型，也被称为AIO(Asynchronous IO)。
异步IO操作基于时间和回调机制，应用操作直接返回，而不会阻塞在那里，当后台处理完成，操作系统会通知相应线程进行后续工作。
关于java.io
IO不仅仅是对文件的操作，网络编程中，比如Socket通信，都是典型的IO操作目标。
输入流/输出流(InputStream/OutputStream)用于读写字节。
Reader/Writer用于操作字符，增加了字符编解码功能。
BufferedOutputStream等带缓冲区的实现，可以避免频繁的磁盘读写，进而提高IO处理效率。
关于java.nio
NIO的主要组成部分：
Buffer，高效的数据容器，除了布尔类型，其他原始数据类型均有相应实现。
Channel，类似在Linux操作系统上看到的文件描述符，是NIO中被用来支持批量式IO的一种抽象。
Selector，是NIO实现多路复用的基础，它提供一种高效的机制，可以检测到注册在Selector上的多个Channel中，是否有Channel处于就绪状态，进而实现单线程对多Channel的高效管理。
NIO如何实现多路复用？
IO多路复用模型中，线程首先发起Select调用，询问内核数据是否准备就绪，内核准备好数据后用户线程再发起read调用。read调用的过程（数据从内核空间->用户空间）还是阻塞的。
目前支持IO多路复用的系统调用，有select,epoll等。
select调用：内核提供的系统调用，它支持一次查询多个系统调用的可用状态。几乎所有的操作系统都支持。 epoll调用：linux 2.6内核，属于select调用的增强版本，优化了IO的执行效率。 IO多路复用模型，通过减少无效的系统调用，减少了对CPU资源的消耗。
Java 中的 NIO ，有一个非常重要的选择器 ( Selector ) 的概念，也可以被称为 多路复用器。通过它，只需要一个线程便可以管理多个客户端连接。当客户端数据到了之后，才会为其服务。</content></entry><entry><title>[Java] 对比 Hashtable、HashMap、TreeMap 有什么不同?</title><url>https://yuancode.net/post/java/draftjava_hashtable_hashmap_treemap/</url><categories><category>面经</category></categories><tags><tag>Java</tag></tags><content type="html"> 对比 Hashtable、HashMap、TreeMap 有什么不同?谈谈你对 HashMap 的掌握。
Hashtable、HashMap、TreeMap都是最常见的一些Map实现，是以键值对的形式存储和操作数据的容器类型。
Hashtable是早期Java类库提供的哈希表实现，本身是同步的，不支持null的key和value。
HashMap是应用更加广泛的哈希表实现，基于哈希表的Map接口实现，行为上大致与HashTable一致，是非线程安全的，可以存储null的key和value。
TreeMap是基于红黑树的一种提供顺序访问的Map，和HashMap不同，它的get、put、remove之类操作的时间复杂度都是O(logn)，可以通过手写Comparator函数来决定键的具体顺序。
+++
扩展：
HashMap的长度为什么是2的幂次方？
​ 为了能让HashMap存取高效，尽量减少碰撞，也就是要尽可能地把数据分配均匀，每个链表的长度大致相同。Hash值范围较大，无法直接使用一个如此大长度的数组。因此通常是对Hash值进行取模运算，得到余数确定存放位置。取模运算的速度在计算机内部不如位运算快，并且取模运算中，如果除数是2的幂次，则等价于与其除数减一的与的操作（hash%length == hash&amp;(length-1)），所以将HashMap的长度设定为2的幂次方比较合适。
HashMap的底层实现
​ JDK1.8之前：
​ 数组和链表结合在一起使用，也就是链表散列。
​ 数组是HashMap的主体
​ JDK1.8之后：
​ 链表长度大于8以后，会调用treeifyBin()方法将链表转化成红黑树。（转换之前会先判断数组长度，数组长度小于64，那么会先进行数组扩容）。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 public class HashMap&lt;K,V> extends AbstractMap&lt;K,V> implements Map&lt;K,V>, Cloneable, Serializable { // 序列号 private static final long serialVersionUID = 362498820763181265L; // 默认的初始容量是16 static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // 最大容量 static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; // 默认的填充因子 static final float DEFAULT_LOAD_FACTOR = 0.75f; // 当桶(bucket)上的结点数大于这个值时会转成红黑树 static final int TREEIFY_THRESHOLD = 8; // 当桶(bucket)上的结点数小于这个值时树转链表 static final int UNTREEIFY_THRESHOLD = 6; // 桶中结构转化为红黑树对应的table的最小容量 static final int MIN_TREEIFY_CAPACITY = 64; // 存储元素的数组，总是2的幂次倍 transient Node&lt;k,v>[] table; // 存放具体元素的集 transient Set&lt;map.entry&lt;k,v>> entrySet; // 存放元素的个数，注意这个不等于数组的长度。 transient int size; // 每次扩容和更改map结构的计数器 transient int modCount; // 临界值(容量*填充因子) 当实际大小超过临界值时，会进行扩容 int threshold; // 加载因子 final float loadFactor; } loadFactor加载因子
表示Hash表中元素的填满的程度。越接近于1，数组中存放的数据（entry）也就越多，会让链表长度增加。
加载因子太大导致查找元素效率低，太小导致数组的利用率低，存放数据会比较分散。默认值0.75f是官方给出的一个比较好的临界值。
threshold临界值
是衡量数组是否需要扩增的标准（if(Size >= threshold)）
threshold=capacity*loadFactor
HashMap常用方法示例
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 package map; import java.util.Collection; import java.util.HashMap; import java.util.Set; public class HashMapDemo { public static void main(String[] args) { HashMap&lt;String, String> map = new HashMap&lt;String, String>(); // 键不能重复，值可以重复 map.put("san", "张三"); map.put("si", "李四"); map.put("wu", "王五"); map.put("wang", "老王"); map.put("wang", "老王2"); // 老王被覆盖 map.put("lao", "老王"); System.out.println("-------直接输出hashmap:-------"); System.out.println(map); /** * 遍历HashMap */ // 1.获取Map中的所有键 System.out.println("-------foreach获取Map中所有的键:------"); Set&lt;String> keys = map.keySet(); for (String key : keys) { System.out.print(key+" "); } System.out.println(); //换行 // 2.获取Map中所有值 System.out.println("-------foreach获取Map中所有的值:------"); Collection&lt;String> values = map.values(); for (String value : values) { System.out.print(value+" "); } System.out.println(); //换行 // 3.得到key的值的同时得到key所对应的值 System.out.println("-------得到key的值的同时得到key所对应的值:-------"); Set&lt;String> keys2 = map.keySet(); for (String key : keys2) { System.out.print(key + "：" + map.get(key)+" "); } /** * 如果既要遍历key又要value，那么建议这种方式，因为如果先获取keySet然后再执行map.get(key)，map内部会执行两次遍历。 * 一次是在获取keySet的时候，一次是在遍历所有key的时候。 */ // 当我调用put(key,value)方法的时候，首先会把key和value封装到 // Entry这个静态内部类对象中，把Entry对象再添加到数组中，所以我们想获取 // map中的所有键值对，我们只要获取数组中的所有Entry对象，接下来 // 调用Entry对象中的getKey()和getValue()方法就能获取键值对了 Set&lt;java.util.Map.Entry&lt;String, String>> entrys = map.entrySet(); for (java.util.Map.Entry&lt;String, String> entry : entrys) { System.out.println(entry.getKey() + "--" + entry.getValue()); } /** * HashMap其他常用方法 */ System.out.println("after map.size()："+map.size()); System.out.println("after map.isEmpty()："+map.isEmpty()); System.out.println(map.remove("san")); System.out.println("after map.remove()："+map); System.out.println("after map.get(si)："+map.get("si")); System.out.println("after map.containsKey(si)："+map.containsKey("si")); System.out.println("after containsValue(李四)："+map.containsValue("李四")); System.out.println(map.replace("si", "李四2")); System.out.println("after map.replace(si, 李四2):"+map); } }</content></entry><entry><title>[Java] 谈谈你对Java平台的理解？</title><url>https://yuancode.net/post/java/java_about_java/</url><categories><category>面经</category></categories><tags><tag>Java</tag></tags><content type="html"> 谈谈你对 Java 平台的理解?“Java 是解释执行”，这句话正确吗?
Java本身是一种面向对象（继承、封装、多态）的语言，最显著的特性有两个方面：一是“编写一次，处处运行”(Write once, run anywhere)（JVM运行.class文件），能够非常容易地获得跨平台能力；二是垃圾收集(GC, Garbage Collection)，Java通过垃圾收集器回收分配内存，大部分情况下，程序员不需要自己操心内存的分配和回收。
“Java 是解释执行”这句话并不准确，Java源代码经过javac编译成.class字节码文件，.class字节码文件经过JVM解释或编译运行。JDK中提供了JIT(Just-In-Time)编译器，也就是通常所说的动态编译器，JIT能够在运行时将热点代码编译成与本地平台相关的机器码，这种情况下部分热点代码就属于==编译执行==，而不是解释执行。同时，Java9提供了AOT编译器，可以直接将所有代码编译成机器码执行。
问题回答扩展：
​ Java语言特性，包括泛型、Lambda等语言特性；
​ 基础类库，包括集合、IO/NIO、网络、并发、安全等基础类库；
​ JVM的一些基础概念和机制，比如Java的类加载机制，常用版本JDK内嵌的Class-Loader，例如Bootstrap、Application和Extension Class-loader；
​ 类加载大致过程：加载、验证、链接、初始化；
​ 自定义Class-Loader；
​ 垃圾收集的基本原理，最常见的垃圾收集器，如SerialGC、Parallel GC、CMS、G1等，对于适用于什么样的工作负载最好也心里有数。</content></entry><entry><title>[Java]Vector、ArrayList、LinkedList的区别</title><url>https://yuancode.net/post/java/draftjava_vector_arraylist_linkedlist/</url><categories><category>面经</category></categories><tags><tag>Java</tag></tags><content type="html"> 对比 Vector、ArrayList、LinkedList 有何区别?
Vector：线程安全的动态数组，扩容时增加1倍。
ArrayList：动态数组，扩容时增加50%。
LinkedList：双向链表，不需要像上面两种一样调整容量。
Vector和ArrayList内部元素以数组形式存储，适合随机访问的场合。
LinkedList进行节点的插入、删除时比较高效。</content></entry><entry><title>[Java基础]int和Integer的区别</title><url>https://yuancode.net/post/java/java_int_and_integer/</url><categories><category>面经</category></categories><tags><tag>Java</tag></tags><content type="html"> int和Integer有什么区别？谈谈Integer的值缓存范围。
Integer是int对应的包装类，它有一个int类型的字段存储数据，并且提供了基本操作，比如数学运算、int和字符串之间转换等。在Java5中，引入了自动装箱和自动拆箱功能1（boxing/unboxing），Java可以根据上下文，自动进行转换，很大程度上简化了相关编程。
int也就是Java中的整形数字，是Java的8个原始数据类型2,Java虽然号称一切都是对象，但是原始数据类型是例外。
关于Integer的值缓存，涉及Java5中的另一个改进。构建Integer对象的传统方式是直接调用构造器new一个对象。但是大部分数据操作都是集中在有限的、较小的数值范围，因此在Java5中新增了静态工厂方法3valueOf，在调用它的时候会利用一个缓存机制，带来明显的性能改进。值默认缓存范围是*-128到127之间*(2^8)。
+++
扩展：
Java对象的内存结构
对象在内存中存储的布局可以分为3块区域：对象头、实例数据和对齐填充。
对象头一般是十六个字节，包括两部分。
​ 第一部分：“Mark Word”，用于存储对象自身的运行时数据，如哈希码、GC分代年龄、锁状态标志、现成持有的锁、偏向线程ID、偏向时间戳等。
​ 第二部分：类型指针，也就是对象指向它的类元数据指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。
实例数据是对象存储的真正有效信息，也是在程序代码中所定义的各种类型的字段内容。无论是从父类继承下来的，还是在子类中定义的，都需要记录起来。
对齐填充并不是必然存在的，起占位符的作用。因为HotSpot VM的 自动内存管理系统要求对象起始地址必须是8字节的整数倍，换句话说，就是对象大小必须是8字节的整数倍。
+++
[1] Java的自动装箱/拆箱功能：https://blog.csdn.net/qq_45570058/article/details/118929927 注意：发生在编译阶段。
[2] Java的8个原始数据类型：boolean、char、byte、short、int、long、float、double。
[3] 静态工厂方法：https://www.runoob.com/design-pattern/factory-pattern.html</content></entry><entry><title>[读书笔记]计算机组成与设计（RISC-V）第1章</title><url>https://yuancode.net/post/computer-organization-and-design-risc-v-edition-1/</url><categories><category>读书笔记</category></categories><tags><tag>RISC-V</tag><tag>计算机组成与设计</tag></tags><content type="html"> 第1章主要是为其余章节奠定基础。介绍了基本概念和定义，对软件和硬件的主要组成部分进行了剖析，展示了如何评估性能和功耗，介绍了集成电路（推动计算机革命的基数），并在最后解释了技术向多核转变的原因。
以下摘自本书引言部分：
在你读完这本书的时候，我们相信你能够回答以下问题：
用C或Java等高级语言编写的程序如何被翻译成机器语言，以及硬件如何执行最终的程序？这些概念是理解软硬件如何影响程序性能的基础。
软件和硬件之间的接口是什么？软件如何指导硬件执行所需的功能？这些概念对理解如何编写软件是至关重要的。
什么因素决定了程序的性能，以及程序员如何改进程序性能？我们将从本书知道，这 取决于原始程序、将该程序转换成计算机语言的软件以及硬件执行该程序的有效性。
硬件设计人员可以使用哪些技术来改善能效？程序员可以做些什么来改变能效？
串行处理近来发展到并行处理的原因和结果是什么？本书给出了这一发展变化的动机，描述了当前支持并行的硬件机制，并评述了新一代*“多核”微处理器*（见第6章)。
自1951 年第一台商用计算机以来，计算机架构师提出的哪些伟大思想奠定了现代计算技术的基础？
第1章 计算机抽象及相关技术 计算机体系结构中的8个伟大思想 面向摩尔定律的设计
​ 摩尔定律：由Intel公司的创始人之一戈登·摩尔在1965年提出，指出单芯片上所集成的晶体管资源每18至24个月翻一番。
摩尔定律 - 维基百科 使用抽象简化设计
​ 提高硬件和软件生产率的主要技术之一是使用抽象（abstraction）来表示不同的设计层次——隐藏底层细节以提供给高层一个更简单的模型。
加速经常性事件
简单的说就是优化调用最频繁的代码/函数。
通过并行提高性能
通过流水线（pipelining）提高性能
通过预测提高性能
​ 在某些情况下，假设从预测错误中恢复的代价并不高，且预测相对准确，则平均来说进行预测并开始工作可能会比等到明确结果后再执行更快。
存储层次
​ 程序员希望存储器速度更快、容量更大、价格更便宜。但是这些需求在目前来说是冲突的。架构师发现可以通过存储层次（hierarchy of memory）来处理这些冲突的需求。速度最快、容量最小并且每位价格最昂贵的存储器处于顶层，而速度最慢、容量最大且每位价格最便宜的存储器处于底层。
​ 这样组织的好处是，高速缓存可以给程序员这样的错觉：主存与存储层次几乎一样快，且与存储层次底层拥有几乎样大的容量和便宜的价格。
通过冗余提高可靠性
​ 通过引入冗余组件来使系统可靠，该组件在系统发生故障时可以替代失效组件并帮助检测故障。</content></entry><entry><title>rCore Tutorial v3 踩坑笔记 - lab0</title><url>https://yuancode.net/post/rcore-lab0-hint/</url><categories><category>操作系统</category></categories><tags><tag>Rust</tag><tag>RISC-V</tag><tag>rCore</tag><tag>踩坑笔记</tag></tags><content type="html"> 记录在进行实验时踩到的一些坑，方便自己以后解决同样的问题，也可以帮助同行者。
由于OS训练营实验指导 文档内容非常粗略，因此建议查看rCore-Tutorial-Book-v3 3.6.0-alpha.1 文档。
踩坑 1. error[E0463]: can&rsquo;t find crate for core 通常状况下，core库以预编译库（precompiled library）的形式与Rust编译器一同发布——这时，core库只对支持的宿主系统有效，而我们自定义的目标系统无效。如果我们想为其它系统编译代码，我们需要为这些系统重新编译整个core库。
解决方案：
使用cargo安装cargo-xbuild
1 2 3 4 $ cargo install cargo-xbuild # 等待安装完成以后 # 其中 riscv64gc-unknown-none-elf 是此次实验中给出的目标平台 $ cargo xbuild --target riscv64gc-unknown-none-elf 2. the riscv64gc-unknown-none-elf target may not be installed 我们只需要下载riscv64gc-unknown-none-elf即可，同时提示信息已经给出了解决方案。
1 $ rustup target add riscv64gc-unknown-none-elf 3. use of undeclared crate or module fmt &amp;&amp; Writenot found in this scope 其实编译器已经告诉了我们如何改正错误。
我们使用了fmt这个create以及Write这个trait，但是我们并没有在代码中使用use引入。
我们可以在main.rs的上方添加use core::fmt::{self, Write};，然后代码便可以正常进行编译。
4. 最后如何运行我们的代码 在文档的最后，文档告诉我们可以使用make run LOG=TRACE来运行我们的代码，但是直接运行的话肯定是行不通的，因为我们的os文件夹中并没有Makefile文件。
解决方案1
拷贝os1项目下的Makefile文件到当前目录:
1 2 3 $ cp ../os1/Makefile . # 然后执行make run $ make run 代码在qemu中正常运行：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 (rustup target list | grep "riscv64gc-unknown-none-elf (installed)") || rustup target add riscv64gc-unknown-none-elf riscv64gc-unknown-none-elf (installed) cargo install cargo-binutils --vers ~0.2 Updating crates.io index Ignored package `cargo-binutils v0.2.0` is already installed, use --force to override rustup component add rust-src info: component 'rust-src' is up to date rustup component add llvm-tools-preview info: component 'llvm-tools-preview' for target 'aarch64-unknown-linux-gnu' is up to date Finished release [optimized] target(s) in 0.04s [rustsbi] RustSBI version 0.2.2, adapting to RISC-V SBI v1.0.0 .______ __ __ _______.___________. _______..______ __ | _ \ | | | | / | | / || _ \ | | | |_) | | | | | | (----`---| |----`| (----`| |_) || | | / | | | | \ \ | | \ \ | _ &lt; | | | |\ \----.| `--' |.----) | | | .----) | | |_) || | | _| `._____| \______/ |_______/ |__| |_______/ |______/ |__| [rustsbi] Implementation : RustSBI-QEMU Version 0.1.1 [rustsbi] Platform Name : riscv-virtio,qemu [rustsbi] Platform SMP : 1 [rustsbi] Platform Memory : 0x80000000..0x88000000 [rustsbi] Boot HART : 0 [rustsbi] Device Tree Region : 0x87000000..0x87000ef2 [rustsbi] Firmware Address : 0x80000000 [rustsbi] Supervisor Address : 0x80200000 [rustsbi] pmp01: 0x00000000..0x80000000 (-wr) [rustsbi] pmp02: 0x80000000..0x80200000 (---) [rustsbi] pmp03: 0x80200000..0x88000000 (xwr) Hello, world! Panicked at src/main.rs:29 Shutdown machine! 解决方案2
1 2 3 4 5 6 $ cargo build --release $ qemu-system-riscv64 \ -machine virt \ -nographic \ -bios ../bootloader/rustsbi-qemu.bin \ -device loader,file=target/riscv64gc-unknown-none-elf/release/os.bin,addr=0x80200000 执行以上两条命令，可以看到我们的代码已经在qemu中正常运行：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 [rustsbi] RustSBI version 0.2.2, adapting to RISC-V SBI v1.0.0 .______ __ __ _______.___________. _______..______ __ | _ \ | | | | / | | / || _ \ | | | |_) | | | | | | (----`---| |----`| (----`| |_) || | | / | | | | \ \ | | \ \ | _ &lt; | | | |\ \----.| `--' |.----) | | | .----) | | |_) || | | _| `._____| \______/ |_______/ |__| |_______/ |______/ |__| [rustsbi] Implementation : RustSBI-QEMU Version 0.1.1 [rustsbi] Platform Name : riscv-virtio,qemu [rustsbi] Platform SMP : 1 [rustsbi] Platform Memory : 0x80000000..0x88000000 [rustsbi] Boot HART : 0 [rustsbi] Device Tree Region : 0x87000000..0x87000ef2 [rustsbi] Firmware Address : 0x80000000 [rustsbi] Supervisor Address : 0x80200000 [rustsbi] pmp01: 0x00000000..0x80000000 (-wr) [rustsbi] pmp02: 0x80000000..0x80200000 (---) [rustsbi] pmp03: 0x80200000..0x88000000 (xwr) Hello, world! Panicked at src/main.rs:29 Shutdown machine! 想达到文档截图中的效果，需要使用第三方库log，具体代码可以参见os1/src/logging.rs和os1/Cargo.toml(引入log库)。</content></entry><entry><title>Rust Quiz #32</title><url>https://yuancode.net/post/rust-quiz-32/</url><categories><category>Rust</category></categories><tags><tag>Rust</tag></tags><content type="html"> 题目 What is the output of this Rust program?
1 2 3 4 5 6 7 8 9 10 11 12 13 fn check(x: i32)-> bool {print!("{}",x);false}fn main(){match(1,2){(x,_)|(_,x)ifcheck(x)=>{print!("3")}_=>print!("4"),}} 代码中的 match 可以被转换为：
1 2 3 4 5 6 7 ifcheck(1){print!("3");}elseifcheck(2){print!("3");}else{print!("4");} 因为 check(x)会打印出x，并且总return false 因此结果应该为 124。
题目变形 变形1 1 2 3 4 5 6 7 8 9 10 11 12 13 fn check(x: i32)-> bool {print!("{}",x);true}fn main(){match(1,2){(x,_)|(_,x)ifcheck(x)=>{print!("3")}_=>print!("4"),}} 输出：13
变形2 1 2 3 4 5 6 7 8 9 10 11 12 13 fn check(x: i32)-> bool {print!("{}",x);x%2==0}fn main(){match(1,2){(x,_)|(_,x)ifcheck(x)=>{print!("3")}_=>print!("4"),}} 输出：123</content></entry><entry><title>C++ 编码风格</title><url>https://yuancode.net/post/c++codestyle/</url><categories><category>软技能</category><category>C++</category></categories><tags><tag>CPP</tag><tag>code style</tag><tag>编码风格</tag></tags><content type="html"> “任何人都能写出机器能看懂的代码，但只有优秀的程序员才能写出人能看懂的代码。”
​ 磨刀不误砍柴工，编码风格我觉得不仅是软件开发行业的共识，更是一种软件开发的文化。之所以讲究编码风格，因为软件的规模越大，协作性要求就越高，软件开发是一件群体性的智力活动，每个人的代码都只有自己懂，每段代码都将成为一个信息孤岛，没法让代码变得可交流、可复用、可维护。一段代码的功能，不仅仅是完成一个任务，也是一种思想的传播，因此注释担当着传递信息的功能，要养成良好的注释习惯和明了易懂注释风格。
空格与空行 留白的艺术
代码示例：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 if(!value.contains("xxx")){ LOGIT(WARNING,"value is incomplete.\n") return; } char suffix[16]="xxx"; int data_len = 100; if(!value.empty()&amp;&amp;value.contains("tom")){ const char* name=value.c_str(); for(int i=0;i&lt;MAX_LEN;i++){ ... // do something } int count=0; for(int i=0;i&lt;strlen(name);i++){ ... // do something } } 修改后：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 if (!value.contains("xxx")) { // if后{前有空格 LOGIT(WARNING, "value is incomplete.\n") // 逗号后有空格 return; // 逻辑联系紧密就不用加空行 } // 新增空行分隔段落 char suffix[16] = "xxx"; // 等号两边有空格 int data_len = 100; // 逻辑联系紧密就不用加空行 // 新增空行分隔段落 if (!value.empty() &amp;&amp; value.contains("tom")) { // &amp;&amp;两边有空格 const char* name = value.c_str(); // 等号两边有空格 // 新增空行分隔段落 for(int i = 0; i &lt; MAX_LEN; i++){ // =;&lt;处有空格 ... // do something } // 新增空行分隔段落 int count = 0; // 等号两边有空格 // 新增空行分隔段落 for(int i = 0; i &lt; strlen(name); i++){ // =;&lt;处有空格 ... // do something } } 起个好名字 ​ 其实命名这件事并不难，主要就在于平时的词汇和经验积累，知道在什么情况下用哪个单词最合适，千万不要偷懒用“谜之缩写”和汉语拼音（更有甚者，是汉语拼音的缩写）。
​ 还可以用一些已经在程序员之间形成了普遍共识的变量名，比如用于循环的 i/j/k、用于计数的 count、表示指针的 p/ptr、表示缓冲区的 buf/buffer、表示变化量的 delta、表示总和的 sum……
​ 关于命名的风格，应用比较广的有三种。
第一种风格叫“匈牙利命名法”，在早期的 Windows 上很流行，使用前缀 i/n/sz 等来表示变量的类型，比如 iNum/szName。它把类型信息做了“硬编码”，不适合代码重构和泛型编程，所以目前基本上被淘汰了。
不过“匈牙利命名法”中也有部分可取之处，比如给成员变量加“m_”前缀（member），给全局变量加“g_”前缀（global），比如 m_count、g_total，这样一看就知道了变量的作用域，在大型程序里还是挺有用的。
第二种风格叫“CamelCase”，也就是“驼峰式命名法”，在 Java 语言里非常流行，主张单词首字母大写，比如 MyJobClass、tryToLock，但这种风格在 C++ 世界里的接受程度不是太高。
第三种风格叫“snake_case”，用的是全小写，单词之间用下划线连接。这是 C 和 C++ 主要采用的命名方式，看一下标准库，里面的 vector、unordered_set、shrink_to_fit 都是这样。
那么究竟应该选用哪种命名风格呢？不如“取百家之长”，混用几种中能让名字辨识度最高的那些优点：
变量、函数名和名字空间用 snake_case，全局变量加“g_”前缀； 自定义类名用 CamelCase，成员函数用 snake_case，成员变量加“m_”前缀； 宏和常量应当全大写，单词之间用下划线连接； 尽量不要用下划线作为变量的前缀或者后缀（比如 local、name），很难识别。 举例：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #define MAX_PATH_LEN 256 //常量，全大写 int g_sys_flag; // 全局变量，加g_前缀 namespace linux_sys { // 名字空间，全小写 void get_rlimit_core(); // 函数，全小写 } class FilePath final // 类名，首字母大写 { public: void set_path(const string&amp; str); // 函数，全小写 private: string m_path; // 成员变量，m_前缀 int m_level; // 成员变量，m_前缀 }; ​ 命名另一个相关的问题是“名字的长度”，一个被普遍认可的原则是：变量 / 函数的名字长度与它的作用域成正比，也就是说，局部变量 / 函数名可以短一点，而全局变量 / 函数名应该长一点。
用好注释 ​ 写出了有好名字的变量、函数和类还不够，要让其他人能“一眼”看懂代码，还需要加上注释。 “注释”在任何编程语言里都是一项非常重要的功能，甚至在编程语言之外，比如配置文件（ini、yml）、标记语言（html、xml），都有注释。一个突出的反例就是 JSON，没有注释功能让许多人都很不适应。
​ 注释表面上的功能很简单，就是给代码配上额外的文字，起到注解、补充说明的作用。但就像是写文章一样，写些什么、写多写少、写成什么样子，都是大有讲究的。
​ 一般来说，注释可以用来阐述目的、用途、工作原理、注意事项等代码本身无法“自说明”的那些东西。
​ 注释必须要正确、清晰、有效，尽量言简意赅、点到为止，不要画蛇添足，更不能写出含糊、错误的注释。
举例：
1 2 template&lt;typename T> int get_value(const T&amp; v); ​ 代码很简单，但可用的信息太少了，你就可以给它加上作者、功能说明、调用注意事项、可能的返回值，等等，这样看起来就会舒服得多：
1 2 3 4 5 6 7 8 // author : xxx // date : 2020-xx-xx // purpose : get inner counter value of generic T // notice : T must have xxx member // notice : return value maybe -1, means xxx, you should xxx template&lt;typename T> int get_value(const T&amp; v); ​ 写注释最好也要有一些标准的格式，比如用统一的“标签”来标记作者、参数说明什么的。可以参考 Javadoc，它算是一个不错的工程化实践。
​ 除了给代码、函数、类写注释，我还建议最好在文件的开头写上本文件的注释，里面有文件的版权声明、更新历史、功能描述，等等。
例如：
1 2 3 4 5 6 // Copyright (c) 2020 by Chrono // // file : xxx.cpp // since : 2020-xx-xx // desc : ... ​ 另外，注释还有一个很有用的功能就是 todo，作为功能的占位符，提醒将来的代码维护者（也许就是你），比如：
1 2 // TODO: change it to unordered_map // XXX: fixme later ​ 总的来说，要写好注释，你要时刻“换位思考”，设身处地去想别人怎么看你的代码，这样的话，上面的那些细则也就不难实施了。
重点总结 用好空格和空行，多留白，让写代码就像写诗一样； 给变量、函数、类起个好名字，你的代码就成功了一半； 给变量、函数、类再加上注释，让代码自带文档，就成了“人能够看懂的代码”。 ​ 有了这个基础，还可以更进一步，使用其他高级规则写出更好的代码，比如函数体不能太长、入口参数不宜过多，避免使用 else/switch 导致层次太深（圈复杂度），等等。
参考资料：指南 &ndash; 章亦春</content></entry><entry><title>关于我</title><url>https://yuancode.net/about.html</url><categories/><tags/><content type="html"> 这个人很懒，所以这里什么也没有。
联系方式 邮箱：duny31030@126.com
微信：18340082257
QQ：461336274
博客：yuancode.net</content></entry></search>